%% Template for ENG 401 reports
%% by Robin Turner
%% Adapted from the IEEE peer review template

%
% note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.

% \documentclass[peerreview,onecolumn]{IEEEtran}
\documentclass[peerreview,compsoc,onecolumn]{IEEEtran} 
\usepackage[noadjust]{cite} % Tidies up citation numbers.
\usepackage{url} % Provides better formatting of URLs.
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables for horizontal lines
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage[flushleft]{threeparttable}

\newcommand{\R}{\mathbb{R}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newenvironment{enumargin}[1]{\begin{enumerate}[leftmargin=#1\textwidth , rightmargin=#1\textwidth]}{\end{enumerate}}

\pagestyle{fancy}
\fancyhead[LE,RO]{\small DDogleg Technical Report: Nonlinear Optimization}

\begin{document}
%\begin{titlepage}
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{DDogleg Technical Report\\ Nonlinear Optimization\\{\Large Revision 2018-1}}

% author names and affiliations

\author{Peter Abeles}
\date{July 19, 2018}

% make the title area
\maketitle
\tableofcontents
\listoffigures
\listoftables
%\end{titlepage}

\IEEEpeerreviewmaketitle
\begin{abstract}
This document describes the implementation details and a little bit of the theory behind unconstrained optimization routines found in DDogleg. Specific algorithms are fully described, implementation details justified, source material cited, tuning best practices described, and benchmark results presented. This document does not fully describe the API, which can be found at \url{http://ddogleg.org}.
\end{abstract}


\section{Optimization Techiques}

\begin{table}[h]
\centering
\caption{\label{definitions:Techniques}Definitions for Techniques}
\begin{tabular}{cl}
$\bm{x}$ & Parameters being optimized. $\bm{x} \in \R^n$ \\
$\bm{x}_k$ & Value of parameters at iteration $k$ \\
$\bm{p}_k$ & Is the step or difference between $\bm{x}_{k+1}-\bm{x}$ in two iterations \\
$f(\bm{x})$ & Scalar cost function being optimized. $f \in \R$ \\
$f_k$ & Short hand for $f(\bm{x}_k)$ \\
$g(\bm{x})$ & Gradient of $f(\bm{x})$. $g \in \R^n$ \\
$g_k$ & Short hand for $g(\bm{x}_k)$ \\
$B(\bm{x})$ & Hessian matrix or an approximation \\ 
$B_k$ & Short hand for $B(\bm{x}_k)$ \\
$H(\bm{x})$ & Inverse Hessian matrix or an approximation \\ 
$H_k$ & Short hand for $H(\bm{x}_k)$ \\
positive definite & Matrix $B$ is positive definite when $y^T B y > 0$ for all non-zero vectors $y$  \\
$s.t.$ & subject to  \\
MAX\_VALUE & The largest possible floating point value
\end{tabular}
\end{table}

This section provides overview of different numerical techniques provided in DDogleg for unconstrained optimization. Techniques described here can often be applied to different problems. Specific implementation details are discussed in the problem's section.
\subsection{Linear Search}

\subsection{Trust Region}
Trust Region refers to a family of optimization methods that operate by assuming a quadratic model is accurate within a local "trust region". The trust region's size is adjusted based on the quadratic model's performance in previous iterations. A summary of Trust Region, as implemented in DDogleg, is found in Algorithm \ref{alg:trust_region}. This implementation\footnote{The more traditional variant described in \cite{numopt2006,fletcher1987} was also considered but found to converge slower in test problems.} is primarily based on the description found in \cite{IMM2004}.

\begin{algorithm}{}
\caption{\label{alg:trust_region}Trust Region}
\begin{algorithmic}[1]
	\State $k \gets 0$, $\Delta_0 \in (0,\Delta_{max})$
	\State \quad $\Delta_{max}$ is the maximum trust region size
	\State \quad $\Delta_{0}$ is the initial trust region size. \Comment{Section \ref{section:init_region_size}}
	\While{$k < k_{\mbox{max}}$ and not $done$}
	\State $p_k$ update by optimizing Eq. \ref{eq:trust_region_subproblem} \Comment{Sections \ref{section:cauchy} and \ref{section:dogleg} }
	\State $\delta_f \gets f(\bm{x}_k) - f(\bm{x}_k + \bm{p}_k)$ \Comment{Actual reduction in score}
	\State $\delta_m \gets m_k(\bm{0})-m_k(\bm{p}_k) = -g^T_k \bm{p} - \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p}$ \Comment{Predicted reduction in score}
	\State $\nu \gets \delta_f / \delta_f$ \Comment{Score reduction ratio} 
	\If{ $\delta_f \le 0$ or $\nu <\frac{1}{4}$} \Comment{Score got worse or the model poor?}
		\State $\Delta_{k+1} \gets \frac{1}{2}\Delta_k$
	\Else
		\If{$\nu>\frac{3}{4}$}
			\Comment{The model is good. Increase the region size?}
			\State $\Delta_{k+1} \gets \mbox{min}(\mbox{max}(3\norm{p_k},\Delta_k),\Delta_{\mbox{max}})$
		\Else
			\State $\Delta_{k+1} \gets \Delta_k$
		\EndIf
	\EndIf
	\If{$\delta_f > 0$ and $\nu > 0$} \Comment{Is the solution acceptable?}
		\State $x_{k+1} \gets x_k + p_k$ \Comment{Update the state}
		\State $done$ $\gets$ $\mbox{F-test}$ or $\mbox{G-test}$ \Comment{Convergence testing}
	\Else
		\State $x_{k+1} \gets x_k$
	\EndIf

	\State $k \gets k + 1$
	\EndWhile
\end{algorithmic}
\end{algorithm}

At every iteration the Trust Region subproblem is solved for, either eactly or approximately:
\begin{equation}
\begin{array}{lr}
\min\limits_{p\in \R^n} m_k(\bm{p}) = f_k + g^T_k \bm{p} + \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p} & s.t. \norm{p} \le \Delta_k
\end{array}
\label{eq:trust_region_subproblem}
\end{equation}
where $p$ is the step or change in state, $B$ is a symmetric matrix which is the Hessian or an approximation thereof. The model $m(\bm{p})$ is a quadratic approximation to $f(x)$. The unconstrained solution to Eq. \ref{eq:trust_region_subproblem} can be easily found by setting the first deriviative to zero:
\begin{equation}
\bm{p} = -\bm{B}^{-1}_k \bm{g}_k
\label{eq:TR_unconstrained_solution}
\end{equation}

An exact solution to (\ref{eq:trust_region_subproblem}) is expensive to compute and approximate methods are typically used instead. The Cauchy Point and Dogleg are included in the DDogleg library.

\subsubsection{Cauchy Point}
\label{section:cauchy} 

The Caunch Point $p^s_k$ is the end point of line segment which starts at $x_{k-1}$ or $p=0$, pointing along unit vector $\hat{p}^s_k$, and has length $\tau_k$. In other words $p^s_k = \tau_k \hat{p}^s_k$. The unknown $\hat{p}^s_k$ is found by solving the subproblem (\ref{eq:trust_region_subproblem}) with only linear terms:
\begin{equation}
\begin{array}{lr}
\hat{p}^s_k = \min\limits_{p\in \R^n} f_k + g_k^T p & s.t. \norm{p} \le \Delta_k
\end{array}
\end{equation}
The length $\tau_k$ is found by minimizing (\ref{eq:trust_region_subproblem}) along direction $\hat{p}^s_k$
\begin{equation}
\begin{array}{lr}
\tau_k = \min\limits_{\tau \ge 0} m_k(\tau v^s_k) & s.t. \norm{\tau v^s_k} \le \Delta_k
\end{array}
\end{equation}

The solution (see Chapter 4 of \cite{numopt2006} for details and diagrams) is as follows:
\begin{equation}
p^s_k = -\tau_k \frac{\Delta_k}{\norm{g_k}}g_k
\label{eq:cauchy_p}
\end{equation}
\begin{equation}
\tau_k = 
	\begin{cases}
		\quad 1 & g_k^T B_k g_k \le 0 \\
		\quad \min\left(1,\norm{g_k}^3/(\Delta_k g_k^T B_k g_k)\right) & g_k^T B_k g_k > 0
	\end{cases}
	\label{eq:cauchy_tau}
\end{equation}

The formulas in (\ref{eq:cauchy_p}) and (\ref{eq:cauchy_tau}) can be improved upon to avoid numerical overflow issues by removing powers of three and division by the step length:
\begin{eqnarray}
\hat{g}_k &=& \frac{g_k}{\norm{g_k}} \\
p^s_k &=& -\bar{\tau}_k \hat{g}_k
\end{eqnarray}
\begin{equation}
\bar{\tau}_k = \begin{cases}
		\quad \Delta_k & \hat{g}_k^T B_k \hat{g}_k\le 0 \\
		\quad \min\left(\Delta_k,\norm{g_k}/(\hat{g}_k^T B_k \hat{g}_k)\right) & \hat{g}_k^T B_k \bar{g}_k > 0
	\end{cases}
\end{equation}
The predicted reduction in score is found using:
\begin{equation}
m_k(\bm{0})-m_k(\bm{p}_k) = \tau_k\left(\norm{g_k} - \frac{\tau_k \hat{g}_k^T B_k \hat{g}_k}{2} \right)
\end{equation}


\subsubsection{Dogleg}
\label{section:dogleg}  

Dogleg considers second order terms to provide a more accurate solution to Eq. \ref{eq:trust_region_subproblem}. The optimal solution, as a function of region size, is a curved trajectory. The Dogleg method approximates this curved trajectory using two line segments. The first line starts at the $x_{k-1}$ and ends at the unconstrained Cauchy point. The second heads towards $p^b$ the solution to the unconstrained version of (\ref{eq:trust_region_subproblem}). As with equations from Cauchy Point, these equations are not traditional (see \cite{numopt2006,IMM2004}) and have been reforumated to avoid powers of three.
\begin{eqnarray}
\hat{g_k} &=& \frac{g_k}{\norm{g_k}} \\
p^u_k &=& -\frac{g_k}{\hat{g_k}^T B_k \hat{g_k}} \\
p^b_k &=& -B^{-1}_k g_k \\
p^{dog}_k &=&
\begin{cases}
	\tau p^u_k & 0 \le \tau < 1 \\
	p^u_k + (\tau -1)(p^b_k-p^u_k) & 1 \le \tau \le 2
\end{cases}
\end{eqnarray}
where $B_k$ is positive definite, and $p^{dog}_k$ is the point selected by the Dogleg method. The solution to $\tau$ can be easily found by solving along each line segment. If $B_k$ is not positive definite then the gradient is used instead.

\begin{algorithm}{}
\caption{\label{alg:dogleg_step}Selection of Dogleg Step}
\begin{algorithmic}[1]
  \If{ $B$ is positive definite}
    \If{$\norm{p^b} < \Delta$} \Comment{Gauss-Newton soluton inside the trust-region?}
      \State $p^{dog} \gets p^b$
    \ElsIf{$\norm{p^u} \geq \Delta$} \Comment{Cauchy point outside the trust-region?}
    \State $p^{dog} \gets \Delta \frac{p^u}{\norm{p^u}}$
    \Else
    \State $p^{dog} \gets $ intersection of $p^u \rightarrow p^b$ and trust-region
    \EndIf
  \Else
   \State $p^{dog} \gets -\Delta\frac{g}{\norm{g}}$ \Comment{Follow gradient to end of trust region}
  \EndIf
\end{algorithmic}
\end{algorithm}

\subsubsection{Scaling and Elliptical Trust Regions} 
\label{section:scaling}

Correct scaling of $\bm{x}$ typically refers to two different issues, both of which can be critical for achieving high accuracy. The first is adjusting the problem being solved such that the variables in $x$ have on average the same scale. The second is applying a linear transform to the system so that at each iteration the linear problem being solved. The first method we will refer to as prescaling and the second as post scaling.

In general, when performing floating point arithematic \cite{goldberg1991every}, you need to avoid mixing very large (e.g. 1e8) numbers with very small (e.g. 1e-12) numbers can causes significant round off errors. Having all the numbers be very small or very large is problematic because that can cause numerical overflow or underflow. Thus it is desirable to have all numbers take on values close to one.

Another reason to scale variables is to reduce the emphasis on sensitive variables. A sensitive variable is one in which a small change in it's value results in a large error, e.g. $1/x^2$ when $x \approx 0$. This can cause the optimization routine to get stuck since any step causes a large error. It's interesting to note that changing the scale will the change the steepest descent direction, but not the solution to the Newton problem \cite{dennis1996}. 

There are a few different ways in which the scale of variables can be adjusted. One of which is to use a diagonal matrix $\bm{D}$ with positive elements. This matrix is then applied to $p$ to created its scaled version $\tilde{p} = \bm{D}p$. The trust region is no longer a circle but an ellipse \cite{numopt2006}, resulting in this alternative trust region subproblem:
\begin{equation}
\begin{array}{lr}
\min\limits_{p\in \R^n} m_k(\bm{p}) = f_k + g^T_k \bm{p} + \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p} & s.t. \norm{\bm{D}p} \le \Delta_k
\end{array}
\end{equation}
As suggested in \cite{numopt2006} this is implemented internally in DDogleg by substituting $\tilde{p}$ for $p$, $D^{-1}g_k$ for $g_k$, and $D^{-1}B_k D^{-1}$ for $B_k$.  

DDogleg offers the following options for scaling:
\begin{enumargin}{0.2}
\item Apply no scaling
\item Automatically select $\bm{D}$ from the Hessian at every iteration
\item User specifies a fixed $\bm{D}$ 
\end{enumargin}
Automatic scaling parameters are typically found using second derivatives $\frac{\partial^2 f}{\partial x^2_i}$, which are found in the Hessian's diagonal elements. Variables with larger second derivatives are more sensitive, thus their movement should be restricted more. The specific formula used in DDogleg is as follows:
\begin{equation}
D_k^{ii} = \max\left( d_{\bigtriangledown},\min\left( \sqrt{|B_k^{ii}|} , d_{\bigtriangleup} \right)\right)
\end{equation}
where $d_{\bigtriangledown}$ is the minimum allowed scaling value and $d_{\bigtriangleup}$ is the maximum. This approach can handle negative definite $B_k$ and has the desirable property \cite{dennis1996} that the diagonal elements in $\tilde{B}_k = D^{-1}B_k D^{-1}$ will typically be $\tilde{B}_k^{ii} \approx 1$, unless clamped or $B_k^{ii}$ is zero. From a numerical perspective, matrices with this property are properly scaled to reduce overflow and can be decomposed with high precision. When configured to automatically scale, DDogleg will update its scaling at every iteration.

There are two primary ways for the user to specify their own scaling in DDogleg. 1) They can pre-scale the data and adjust their forumlas. 2) They can provide a scaling vector which contains the diagonal elements in $D$. The former is arguably the best way while the later is easier. If the former is done then automatic scaling can still be applied, ensuring that the Hessian matrix is well suited for decomposition. A third option, for advanced users, is to override a class in DDogleg and change the scaling to any arbitrary function you wish.

\subsubsection{Initial Region Size} 
\label{section:init_region_size}

Selection of the initial trust region size $\Delta_0$ is important but typically not discussed in reference material \cite{fletcher1987,numopt2006,IMM2004} in detail. Initial region size is typically considered a tuning parameter that the user is supposed to select through trial and error. While the Trust region size is dynamically adjusted at each iteration in the Trust Region approach, the initial selection of the trust region size can significantly influence the final convergence.

Here is an example of a possible failure mode when the trust region's size is poorly selected. With the Dog Leg method, if $\Delta_0$ is too small then a Cauchy step is selected repeadidly. The Cauchy Point takes much smaller steps, increasing the chances of getting stuck in a local minimum.

DDogleg provides two automatic methods for finding the initial region size. 1) \emph{Uncontrained initial step} and 2) \emph{Cauchy initial step}. With the unconstrained method the selected algorithm for choosing a step is given a trust region of MAX\_VALUE. The step it selects is used and the trust region is then set to the length of that step. This works well in many problems but can be overly agressiveand take a very large step into a distant plataue. The Cauchy initial step method computes the length of a Cauchy step, then sets the region size to be 10x that. This estimate tends to be conservative will in general converge but can make convergence slow.

If the automatic methods fail to produce acceptable results then manual tuning will be necissary. One possible manual tuning procedure is to start with $\Delta_0=1$ then trying $\Delta_0=100$, and if results improved try $\Delta_0=10000$. If results don't get better try $0.1$ or other fractions of one.

Recommended Procedure for Selection of Initial Trust Region Size:
\begin{enumargin}{0.2}
\item Turn on verbose output and examine the progress
\item Start with automatic selection using \emph{unconstrained initial step}
\item If this fails then try \emph{Cauchy initial step}
\item If performance is still poor follow manual tuning procedure
\end{enumargin}
For instructions on how to switch between the methods described here consult the JavaDoc of ConfigTrustRegion.

A comparison of different initial conditions for different 'toy' problems is shown in Table \ref{results:initial_region}. In these scenarios, the Automatic Unconstrained method correctly selected the best initial conditions while all the other methods either tied unconstrained's performance or clearly made a poor choice. Unfortunately, these results don't extrapolate to all problems and there are situations where the unconstrained method results in failure. For that reason, the default method is in DDogleg is the more conservative Automatic Cauchy.

\begin{table}[h]
\centering
\begin{threeparttable}
\caption{\label{results:initial_region}Comparison of Initial Region Size}
\begin{tabular}{|l||c|c|c||c|c|c||c|c|c||c|c|c|}
\hline
Problem        & \multicolumn{3}{c||}{Automatic} & \multicolumn{3}{c||}{Automatic} & \multicolumn{3}{c||}{Manual} & \multicolumn{3}{c|}{Manual}\\
               & \multicolumn{3}{c||}{Unconstrained} & \multicolumn{3}{c||}{Cauchy} & \multicolumn{3}{c||}{1} & \multicolumn{3}{c|}{100} \\
\hline
               & Fit     & G  & B  & Fit     & G  & B   & Fit     & G  & B  & Fit     & G  & B\\
\hline
Powel          & 2.0e-17 & 17 & 17 & 2.9e-17 & 30 & 26  & 4.9e-18 & 23 & 19 & 2.0e-17 & 17 & 17 \\
Powel Singular & 7.3e-11 & 11 & 11 & 2.3e-10 & 13 & 13  & 6.7e-11 & 11 & 11 & 7.3e-11 & 11 & 11 \\
Helical Valley & 2.5e-26 & 11 & 8  & 5.1e-18 & 11 & 11  & 4.1e-33 & 9  & 8  & 2.7e-26 & 16 & 8\\
B.S. Powell    & 4.2e-31 & 25 & 18 & 3.7e-23 & 73 & 58  & 2.2e-31 & 25 & 18 & 0       & 62 & 43 \\
Bundle 2D      & 3.7e-10 & 111& 36 & 7.0e-18 & 111& 36  & 9.0e-10 & 251& 93 & 3.3e-10 & 112 & 37 \\
Bundle 2D [1]  & 7.0e-19 & 4  & 4  & 7.0e-18 & 4  & 4   & 1.5e-15 & 5  & 5  & 7.0e-18 & 4 & 4 \\ \hline
\end{tabular}
\begin{tablenotes}
\small
\item \emph{Fit} is the final fit score where zero is a perfect fit. \emph{G} is the number of times the gradient was computed. \emph{B} is the number of times the Hessian was computed. B is by far the most expensive step.
\item Unless specified otherwise, all methods use Dogleg with a Cholesky solver. 
\item [1] Uses QR with column pivots instead of Cholesky and can handle the nearly singular initial state.
\end{tablenotes}
\end{threeparttable}
\end{table}

\subsection{Schur Complement}
For sparse systems with a specific structure, the Schur Complement can be used to greatly reduce the computational cost. What would have taken hours or days to solve can be solved in seconds or minutes. Bundle Adjustment is one such problem \cite{triggs1999bundle}. The power of the Schur Complement comes from breaking the system into sub-problems. Since the matrix has a special structure, sparse fill in \cite{davis2006} is avoided its highly efficient.

Let $M \in \R^{N,N}$ be an invertible square matrix which has been broken up into four submatrices. It can be factorized as follows:
\begin{equation}
M = \begin{bmatrix}
A & B \\
C & D
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 \\
C A^{-1} & 1
\end{bmatrix}
\begin{bmatrix}
A & 0 \\
0 & \bar{D}
\end{bmatrix}
\begin{bmatrix}
1 & A^{-1}B \\
0 & 1
\end{bmatrix}
\end{equation}
It can then be shown that
\begin{equation}
\bar{D} = D - C A^{-1}B
\end{equation}
This is known as the Schur complement of the block A of matrix M. The Schur comlpement of block D of matrix M can also be found:
\begin{equation}
\bar{A} = A - B D^{-1}C
\end{equation}
We will discuss the former but either can be used. Which one is prefered is simply the one which can be computed fastest and is dependent on the matrix's structure.

These relationships can then be used to solve the following system:
\begin{equation}
\begin{bmatrix}
A & B \\
C & D
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\ b_2
\end{bmatrix}
\end{equation}

\begin{algorithm}{}
\caption{\label{alg:schur_complement}Schur Complement to solve a reduced system}
\begin{algorithmic}[1]
	\State $\bar{D} = D - C A^{-1} B$
	\State $\bar{b}_2 = b_2 - C A^{-1} b_1$  
	\State $\bar{D} x_2 = \bar{b}_2$         \Comment{Reduced System}
	\State $A x_1 = b_1 - B x_2$
\end{algorithmic}
\end{algorithm}

For the least squares problem, the Schur Complement is applied to the Jacobian inner product:
\begin{equation}
J^T J =
\begin{bmatrix}
A & B \\
B^T & D
\end{bmatrix}
\end{equation}
Symmetry can be taken advantage of in matrix multiplication and when solving the system, which DDogleg does.

\subsection{Linear Algebra}

Linear algebra and matrix operations are the workhorses that non-linear optimization is built upon. Of particular importance are algorithms capable of solving equations of the form:
\begin{equation}
\bm{A}\bm{b} = \bm{y}
\end{equation}
where $\bm{A} \in \R^{m,n}$, $\bm{b} \in \R^n$ is unknown, and $\bm{y} \in \R^m$. The two solvers most frequently used in DDogleg are Cholesky and QR with column pivots. The importantance of choosing the correct solver can be seen in Table \ref{results:initial_region}. A discussion of difference between different solvers and efficient computations is beyound the reach of this document.

DDogleg has a modular design and abstracts aware specific implementations details allowing different libraries and solvers to be used. This design allows most of the same code to be shared between sparse and dense implementations. The source of all default linear algebra operations in DDogleg is Efficicient Java Matrix Library (EJML) \cite{ejml2018}. If you wish to learn more about the computational side of linear algebra then ``Fundamentals of Matrix Computations'' \cite{watkins2010} and ``Direct Methods for Sparse Linear Systems'' \cite{davis2006} are recommended for dense and sparse systems, respectively.

\section{Unconstrained Minimization}

\begin{table}[h]
\centering
\caption{\label{definitions:UM}Definitions and API for Unconstrained Minimization}
\begin{tabular}{cl}
\textit{FunctionNtoS} & Interface for function $f(\bm{x})$ \\
\textit{FunctionNtoN} & Interface for gradient $g(\bm{x})$ \\
& Can be computed numerically \\
\textit{UnconstrainedMinimization} & Interface for unconstrained minimization
\end{tabular}
\end{table}

\begin{table}[h]
\caption{\label{summary:UM}Summary of Unconstrained Minimization Methods.}
\centering
\begin{tabular}{lcccccc}
Method & Iteration & Convergence & Singular & Negative-Definite & Dense & Sparse \\[1ex]
\hline
Quasi-Newton BFGS        & $O(N^2)$ & Super Linear & ?   & ?   & Yes &  \rule{0pt}{2.6ex} \\
Trust Region BFGS Cauchy & $O(N^2)$ & Linear       & Yes & Yes & Yes & Yes  \\
Trust Region BFGS Dogleg & $O(N^2)$ & Super Linear & [1] & [1] & Yes & Yes  \\[1ex]
\hline
\multicolumn{6}{l}{
\begin{minipage}{0.6\textwidth}
\centering
\vspace{2mm}
\begin{itemize}[leftmargin=*]
\item \emph{Iteration}: Runtime complexity of update step. $N$ is number of parameters.
\item \emph{Convergence}: how fast it converged.
\item \emph{Singular}: indicates that it can process singular systems.
\item \emph{Negative-Definite}: indicate that it can process negative definite systems
\item \emph{Dense} and \emph{Sparse}: indicate that dense and/or sparse matrices can be processed. 
\item {[1]} Switches to Cauchy in this situation.
\end{itemize}
\end{minipage}
 }
\end{tabular}
\end{table}

Unconstrained minimization seeks to find a set of parameters which minimizes a function, e.g.:
\begin{equation}
\min\limits_{\bm{x} \in \R^N} f(\bm{x})
\end{equation}
where $\bm{x}$ is an $N$-dimensional vector and $f : \R^N \Rightarrow \R $ is a function which outputs a scalar. A global minimum $x^*$ is a minimum such that $f(x^*) \le f(x)$ for all $x$. Local minimums are ones where $f(x^*) \le f(x)$ for all $x \in \mathcal{N}$, where $\mathcal{N}$ is bounded set of subset of $\R^N$. For most problems of interest to users of this library the best that can be found is a local minimum which is better than most of the other local minimums. A good introduction to the theory in this subject can be found in \cite{numopt2006}.

In DDogleg, solutions to this problem use the function's gradient and Hessian to find a minimum. Convergence is found by examining the function's rate of change and the gradient, Section \ref{sec:unmin_convergence}. Computing the Hessian is often tedious and computationally expensive so iterative approximations of the Hessian, Section \ref{sec:hessian_approx}. The remaining sections discuss specific implementation details of applying general purpose algorithms to this problem.

\subsection{Convergence Test}
\label{sec:unmin_convergence}

All unconstrained minimization algorithms in DDogleg use the same convergence tests. F-test checks the function's value to see if it has converged. G-test checks the gradient to see if it has converged. To disable a test assign it a value less than zero.

\begin{center}
\begin{tabular}{lc}
F-test & $ftol \cdot f(x)  \leq f(x) - f(x+p)$ \\
G-test & $gtol \leq \norm{\bm{g}(x)}_\infty$ \\
\end{tabular}
\end{center}
 
\subsection{Hessian Approximation}
\label{sec:hessian_approx}

Unconstrianed minimization techniques need a way to estimate the Hessian. Exact methods of calculating the Hessian can be difficult to derive and expensive to compute. Algorithms which utilize exact methods have faster convergence but this is often offset by additional computational cost \cite{numopt2006}. DDogleg uses gradient based methods for estimating the Hessian. DFP \cite{davidonDFP} to estimate the Hessian and BFGS (Broyden-Fletcher-Goldfarb-Shanno) \cite{fletcher1987,numopt2006}\footnote{A quick search failed to assertain the first paper which fully described BFGS. What appears to be a precursor is discussed in \cite{fletcher1987} and \cite{numopt2006} fully describes the method but provides no citations.} to estimate the inverse hessian.

\begin{flalign}
\text{DFP} && \bm{B}_{k+1} &= (I- \rho_k \gamma_k s_k^T) \bm{B}_k (I - \rho_k s_k \gamma_k^T) + \rho_k \gamma_k \gamma_k^T && \\
\text{BFGS} && \bm{H}_{k+1} &= H_k - \frac{H_k \gamma_k \gamma_k^T H_k }{\gamma_k^T H_k \gamma y_k} + \frac{s_k s_k^T}{y_k^T s_k} &&
\end{flalign}
\begin{equation*}
\rho_k=\frac{1}{\gamma_k^T s_k}
\end{equation*}
where $H_k = B_k^{-1}$, $s_k = x_{k+1}-x_k$, and $y_k = \nabla f_{k+1} - \nabla f_k$.

DDogleg does not explictly provide support for using an exact Hessian. If you wish to use an exact Hessian this can be accomplished with a bit of coding by extending base classes in DDogleg. Search code for where BFGS is being used, extend that class, and override the function where the Hessian is estimated. For example, \textit{UnconMinTrustRegionBFGS} can be used to create your own exact Hessian unconstrained minimization trust region implementation.

\subsection{Trust Region}

Implementation Details:
\begin{enumargin}{0.2}
    \item The Hessian is initialized with an identity matrix. 
	\item The Hessian and inverse is iteratively approximated using DFP and BFGS.
	\item The Hessian is only updated when the Wolfe condition is meet
	\item Dogleg-BFGS avoids $O(N^3)$ matrix decomposition by computing the inverse Hessian directly with BFGS in $O(N^2)$ time.
\end{enumargin}

Future Work:
\begin{enumargin}{0.2}
	\item Remove the need to compute $B_k$ and $H_k$ by directly computing the Cholesky factors of $B_k$. 
\end{enumargin}

\section{Unconstrained Least-Squares}
\begin{table*}[h]
\centering
\begin{tabular}{cl}
$\bm{x}$ & Parameter vector which is being optimized and has $n$ elements. $x \in \R^N$ \\
$f(\bm{x})$ & Scalar error function being optimized. $f \ge 0$ \\
$f_k$ & Short hand for $f(\bm{x}_k)$ \\
$\bm{F}(\bm{x})$ & Residual function from $\R^N \rightarrow \R^M$ \\
$\bm{J}(\bm{x})$ & Jacobian of residual function \\
$B(\bm{x})$ & Hessian approximation and is set to $B=\bm{J}^T\bm{J}$ \\
$g(\bm{x})$ & Gradient of $f(\bm{x})$, which is $\bm{J}(\bm{x})^T  \bm{F}(\bm{x})$ \\
$g_k$ & Short hand for $g(\bm{x}_k)$ \\
$\alpha$ & Mixing coefficent for Levenberg's and Marquardt's equations \\
\textit{FunctionNtoM} & Interface for residuals $\bm{F}(\bm{x}) \in \R^M$ \\
\textit{FunctionNtoMxN} & Interface for Jacobian $\bm{J}(\bm{x}) \in \R^{M,N}$ \\
& Can be computed numerically \\
\textit{UnconstrainedLeastSquares} & High level interface for this unconstrained least squares \\
\textit{UnconstrainedLeastSquaresSchur} & Least-Squares using Schur Complement
\end{tabular}
\caption{\label{definitions:UNLS}Definitions and API for Unconstrained Nonlinear Least-Squares}
\end{table*}

\begin{table}[h]
\caption{\label{summary:UM}Summary of Unconstrained Least-Squares Methods.}
\centering
\begin{tabular}{lcccccc}
Method & Iteration & Convergence & Singular & Dense & Sparse & Schur \\[1ex]
\hline
Trust Region LS Cauchy & $O(N^3)$ & Linear       & Yes  & Yes  & Yes & Yes \rule{0pt}{2.6ex}  \\
Trust Region LS Dogleg & $O(N^3)$ & Super Linear & [1]  & Yes  & Yes & Yes \\
Levenberg-Marquardt    & $O(N^3)$ & Super Linear & [2]  & Yes  & Yes & Yes \\[1ex]
\multicolumn{6}{l}{
\begin{minipage}{0.6\textwidth}
\centering
\vspace{2mm}
\begin{itemize}[leftmargin=*]
\item \emph{Iteration}: Runtime complexity of update step. $N$ is number of parameters.
\item \emph{Convergence}: how fast it converged.
\item \emph{Singular}: indicates that it can process singular systems.
\item \emph{Negative-Definite}: indicate that it can process negative definite systems
\item \emph{Dense} and \emph{Sparse}: indicate that dense and/or sparse matrices can be processed. 
\item \emph{Schur}: If a variant is available that uses the Schur Complement
\item {[1]} Switches to Cauchy in this situation.
\item {[2]} Depends on solver and mixing coefficient, but in most configurations it can handle singular systems.
\end{itemize}
\end{minipage}
 }
\end{tabular}
\end{table}

Unconstrained Least-Squares is a special case of Unconstrained Minimization. It refers to a problem where the function being optimized has the form
\begin{equation}
\label{eq:residual_error}
\min\limits_{\bm{x}} f(\bm{x})=\frac{1}{2}\sum^m_{j=1} r^2_j(\bm{x})
\end{equation}
where $r_j(\bm{x}) = $ is a scalar function which outputs the residual (predicted value subtracted the observed value) or error. By definition $f(\bm{x}) \ge 0$. Matrix notation can also be used to defined \ref{eq:residual_error}:
\begin{equation}
\min\limits_{\bm{x}} f(\bm{x}) =\frac{1}{2} \bm{F}(\bm{x})^T \bm{F}(\bm{x}) = \frac{1}{2} \norm{\bm{F}(\bm{x})}^2_2
\end{equation}
where $\bm{F}(\bm{x}) = [ r_1(\bm{x}) , r_2(\bm{x}) , \cdots , r_m(\bm{x}) ]^T$. Then the Jacobian is defined as:
\begin{eqnarray}
\bm{J}(\bm{x}) &=&  \left[ \begin{array}{c}\nabla r_1(\bm{x})^T \\ \nabla r_2(\bm{x})^T \\ \vdots \\ \nabla r_m(\bm{x})^T \end{array}\right] \\
\nabla r_j(\bm{x})^T &=& \left[ \frac{\partial r_j}{\partial x_1},\frac{\partial r_j}{\partial x_2}, \cdots , \frac{\partial r_j}{\partial x_n} \right]^T
\end{eqnarray}
and the Gradient as
\begin{eqnarray}
\nabla f(\bm{x}) = \bm{g}(\bm{x}) &=& \sum^m_{j=1}r_j(\bm{x})\nabla r_j(\bm{x}) \\
&=& \bm{J}(\bm{x})^T \bm{F}(\bm{x})
\end{eqnarray}

\subsection{Convergence Test}

The same convergence tests used in unconstrained minimization are used with least squares:
\begin{center}
\begin{tabular}{lc}
F-test & $ftol \cdot f(x)  \leq f(x) - f(x+p)$ \\
G-test & $gtol \leq \norm{\bm{g}(x)}_\infty$ \\
\end{tabular}
\end{center}

\subsection{Levenberg-Marquardt}

Levenberg-Marquardt (LM) is a Trust Region based algorithm which was created before Trust Region has been formally been defined \cite{numopt2006,fletcher1987,dennis1996}. The original formulation proposed by Levenberg \cite{levenberg1944} involves solving the system below at every iteration:
\begin{equation}
\label{eq:levenberg}
(J_k^T J_k + \lambda I) p_k = -g_k
\end{equation} 
where $\lambda$ is the damping factor that's adjusted at each iteration. Later on Marquardt \cite{marquardt1963} noted that as $\lambda$ increased information in $J_k^T J_k$ is used less, slowly convergence as it becomes a steepest descent search. Instead Levenberg proposed the following adjustment:
\begin{equation}
\label{eq:marquardt}
(J_k^T J_k + \lambda \mbox{diag}(J_k^T J_k)) p_k = -g_k
\end{equation} 
This would result in larger steps along the direction with smaller gradient, avoiding slow convergence.

DDogleg's implementation (Algorithm \ref{alg:levenberg_marquardt}) is primarily based upon the description found in \cite{IMM2004} but with the ability to choose a mixture of Levenberg's and Marquardt's. The more widely cited algorithm found in \cite{fletcher1987} and others was found to converge slower. Mixing \ref{eq:levenberg} and \ref{eq:marquardt} is advantagous because it allows you to avoid the negatives of either approach. If the derivative of an element is zero then Marquardt's forumation can produce singular matrices. While Levenberg's forumation will always produce a positive-definate matrix as long as $\lambda$ is greater than zero. The amount of mixing is specified using $\alpha$. If $\alpha=1$ then (\ref{eq:levenberg}) is used while if $\alpha=0$ then (\ref{eq:marquardt}) is used. Any value between 0 and 1 will result in a mixture of the two equations.

The classes \emph{FactoryOptimization} and \emph{FactoryOptimizationSparse} provide easy to use functions for constructing specific implementations of Levenberg-Marquardt. As inputs they take in a \emph{ConfigLevenbergMarquardt} and a boolean flag called \emph{robust}. If the robust flag is set to true then a solver based on QR with column pivots is used and if false then it used Cholesky decomposition. The robust variant can handle degenerate matrices found in the Marquardt's forumation. DDogleg does not provide support for solving the least squares forumation, i.e. $J_k p_k = -F_k$, due to the increase in computational cost and code complexity having no noticable improvement in convergence in any situation the author is aware of.

Scaling is done using the same methods described in Section \ref{section:scaling}.

\begin{algorithm}{}
\caption{\label{alg:levenberg_marquardt}Levenberg-Marquardt}
\begin{algorithmic}[1]
	\State $k \gets 0$, $\nu \gets 2$
  	\State $B_k = J_k^T J_k$
	\While{$k < k_{\mbox{max}}$ and not $done$}
		\State Solve $\left(B_k + \lambda \left(\alpha I + (1-\alpha)\mbox{diag}(B_k) \right)\right) p_k = -g_k$ \Comment{LM Step}
		\State $\delta_f \gets f(\bm{x}_k) - f(\bm{x}_k + \bm{p}_k)$ \Comment{Actual reduction in score}
		\State $\delta_m \gets m_k(\bm{0})-m_k(\bm{p}_k) = -g^T_k \bm{p} - \frac{1}{2}\bm{p}^T J_k^T J_k \bm{p}$ \Comment{Predicted reduction in score}
		\State $\nu \gets \delta_f / \delta_f$ \Comment{Score reduction ratio} 
		\If{ $\delta_f \ge 0$} \Comment{Score get better?}
			\State $\lambda \gets \lambda \cdot \mbox{max}(1/3 , 1-(2\nu-1)^3)$
			\State $\nu = 2$
			\State $p_{k+1} \gets p_k$
			\State $done$ $\gets$ $\mbox{F-test}$ or $\mbox{G-test}$ \Comment{Convergence testing}
		\Else
			\State $\lambda \gets \nu \lambda$ \Comment{Follow the gradient more and decrease the step size}
			\State $\nu = 2\nu$
		\EndIf
		\State $k \gets k + 1$
	\EndWhile
\end{algorithmic}
\end{algorithm}


\subsection{Trust Region}

Application of Trust Region to the Least Squares problem is straight forwards. Everything previously discussed still applies with the following variables defined as:
\begin{eqnarray}
\bm{g}_k &=& J^T_k F_k  \\
\bm{B}_k &=& J_k^T J_k
\end{eqnarray}

\bibliographystyle{IEEEtran}
\bibliography{mybib}


\end{document}
