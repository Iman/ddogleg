%% Template for ENG 401 reports
%% by Robin Turner
%% Adapted from the IEEE peer review template

%
% note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.

% \documentclass[peerreview,onecolumn]{IEEEtran}
\documentclass[peerreview,compsoc,onecolumn]{IEEEtran} 
\usepackage[noadjust]{cite} % Tidies up citation numbers.
\usepackage{url} % Provides better formatting of URLs.
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables for horizontal lines
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{fancyhdr}

\newcommand{\R}{\mathbb{R}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newenvironment{enumargin}[1]{\begin{enumerate}[leftmargin=#1\textwidth , rightmargin=#1\textwidth]}{\end{enumerate}}

\pagestyle{fancy}
\fancyhead[LE,RO]{\small DDogleg Technical Report: Nonlinear Optimization}

\begin{document}
%\begin{titlepage}
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{DDogleg Technical Report\\ Nonlinear Optimization\\{\Large Version 2018-1}}

% author names and affiliations

\author{Peter Abeles}
\date{July 19, 2018}

% make the title area
\maketitle
\tableofcontents
\listoffigures
\listoftables
%\end{titlepage}

\IEEEpeerreviewmaketitle
\begin{abstract}
This document describes the implementation details and a little bit of the theory behind unconstrained optimization routines found in DDogleg. Specific algorithms are fully described, implementation details justified, source material cited, tuning best practices described, and benchmark results presented. This document does not fully describe the API, which can be found at \url{http://ddogleg.org}.
\end{abstract}


\section{Optimization Techiques}

\begin{table}[h]
\centering
\caption{\label{definitions:Techniques}Definitions for Techniques}
\begin{tabular}{cl}
$\bm{x}$ & Parameters being optimized. $\bm{x} \in \R^n$ \\
$\bm{x}_k$ & Value of parameters at iteration $k$ \\
$f(\bm{x})$ & Scalar cost function being optimized. $f \in \R$ \\
$f_k$ & Short hand for $f(\bm{x}_k)$ \\
$g(\bm{x})$ & Gradient of $f(\bm{x})$. $g \in \R^n$ \\
$g_k$ & Short hand for $g(\bm{x}_k)$ \\
$B(\bm{x})$ & Hessian matrix or an approximation \\ 
$B_k$ & Short hand for $B(\bm{x}_k)$ \\
$H(\bm{x})$ & Inverse Hessian matrix or an approximation \\ 
$H_k$ & Short hand for $H(\bm{x}_k)$ \\
positive definite & Matrix $B$ is positive definite when $y^T B y > 0$ for all non-zero vectors $y$  \\
$s.t.$ & subject to  \\
MAX\_VALUE & The largest possible floating point value
\end{tabular}
\end{table}

This section provides overview of different numerical techniques provided in DDogleg for unconstrained optimization. Techniques described here can often be applied to different problems. Specific implementation details are discussed in the problem's section.
\subsection{Linear Search}

\subsection{Trust Region}
Trust Region refers to a family of methods that operate by assuming a quadratic model can accurately represent the true function within a local "trust region". The size of the trust region is adjusted based on the performance of the quadratic model. A summary of the trust region can be found in Algorithm \ref{alg:trust_region}. The implementation found in DDogleg\footnote{The variant described in \cite{numopt2006,fletcher1987} was also considered but took significantly longer to converge in test problems.} is primarily based on the description found in \cite{IMM2004}.

\begin{algorithm}{}
\caption{\label{alg:trust_region}Trust Region}
\begin{algorithmic}[1]
	\State $k \gets 0$, $\Delta_0 \in (0,\Delta_{max})$
	\State \quad $\Delta_{max}$ is the maximum trust region size
	\State \quad $\Delta_{0}$ is the initial trust region size. \Comment{Section \ref{section:init_region_size}}
	\While{$k < k_{\mbox{max}}$ and not $done$}
	\State $p_k$ update by optimizing Eq. \ref{eq:trust_region_subproblem} \Comment{Sections \ref{section:cauchy} and \ref{section:dogleg} }
	\State $\delta_f \gets f(\bm{x}_k) - f(\bm{x}_k + \bm{p}_k)$ \Comment{Actual reduction in score}
	\State $\delta_m \gets m_k(\bm{0})-m_k(\bm{p}_k) = -g^T_k \bm{p} - \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p}$ \Comment{Predicted reduction in score}
	\State $\nu \gets \delta_f / \delta_f$ \Comment{Score reduction ratio} 
	\If{ $\delta_f \le 0$ or $\nu <\frac{1}{4}$} \Comment{Score got worse or the model poor?}
		\State $\Delta_{k+1} \gets \frac{1}{2}\Delta_k$
	\Else
		\If{$\nu>\frac{3}{4}$}
			\Comment{The model is good. Increase the region size?}
			\State $\Delta_{k+1} \gets \mbox{min}(\mbox{max}(3\norm{p_k},\Delta_k),\Delta_{\mbox{max}})$
		\Else
			\State $\Delta_{k+1} \gets \Delta_k$
		\EndIf
	\EndIf
	\If{$\delta_f > 0$ and $\nu > 0$} \Comment{Is the solution acceptable?}
		\State $x_{k+1} \gets x_k + p_k$ \Comment{Update the state}
		\State $done$ $\gets$ $\mbox{F-test}$ or $\mbox{G-test}$ \Comment{Convergence testing}
	\Else
		\State $x_{k+1} \gets x_k$
	\EndIf

	\State $k \gets k + 1$
	\EndWhile
\end{algorithmic}
\end{algorithm}

At every iteration a subproblem is solved where an exact or approximate solution for $p$ is found.
\begin{equation}
\begin{array}{lr}
\min\limits_{p\in \R^n} m_k(\bm{p}) = f_k + g^T_k \bm{p} + \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p} & s.t. \norm{p} \le \Delta_k
\end{array}
\label{eq:trust_region_subproblem}
\end{equation}
where $B$ is a symmetric matrix and is the Hessian or an approximation of the Hessian. The model $m(\bm{p})$ is a quadratic approximation to $f(x)$, the function being optimized. Without constraints  the solution to Eq. \ref{eq:trust_region_subproblem} can be easily found by setting first deriviative equal to zero and you get:
\begin{equation}
\bm{p} = -\bm{B}^{-1}_k \bm{g}_k
\label{eq:TR_unconstrained_solution}
\end{equation}

There are many types of Trust Region algorithms. One important design decision is how to solve for $p$ in Eq. \ref{eq:trust_region_subproblem}. We will describe two approaches which are implemented in the DDogleg library; Cauchy Point, and Dogleg.

\subsubsection{Scaling and Elliptical Trust Regions} 

Correct scaling of variables in $x$ is critical for achieving high accuracy, especially for problem with a large number of parameters. When variable are correctly scaled their values will on average have the same order of magnitude. Mixing very large (e.g. 1e8) numbers with very small (e.g. 1e-12) numbers causes significant round off errors. 

Another reason to scale variables is to reduce the emphasis on sensitive variables. A sensitive variable is one in which a small change in it's value results in a large error, e.g. $1/x^2$ when $x \approx 0$. This can cause the optimization routine to get stuck since any step causes a large error. It's interesting to note that changing the scale will the change the steepest descent direction, but not the solution to the Newton problem \cite{dennis1996}. 

There are a few different ways in which the scale of variables can be adjusted. One of which is to use a diagonal matrix $\bm{D}$ with positive elements. This matrix is then applied to $p$ to created its scaled version $\tilde{p} = \bm{D}p$. The trust region is no longer a circle but an ellipse \cite{numopt2006}, resulting in this alternative trust region subproblem:
\begin{equation}
\begin{array}{lr}
\min\limits_{p\in \R^n} m_k(\bm{p}) = f_k + g^T_k \bm{p} + \frac{1}{2}\bm{p}^T \bm{B}_k \bm{p} & s.t. \norm{\bm{D}p} \le \Delta_k
\end{array}
\end{equation}
As suggested in \cite{numopt2006} this is implemented internally in DDogleg by substituting $\tilde{p}$ for $p$, $D^{-1}g_k$ for $g_k$, and $D^{-1}B_k D^{-1}$ for $B_k$.  

DDogleg offers the following options for scaling:
\begin{enumargin}{0.2}
\item Apply no scaling
\item Automatically select $\bm{D}$ from the Hessian at every iteration
\item User specifies a fixed $\bm{D}$ 
\end{enumargin}
Automatic scaling parameters are typically found using second derivatives $\frac{\partial^2 f}{\partial x^2_i}$, which are found in the Hessian's diagonal elements. Variables with larger second derivatives are more sensitive, thus their movement should be restricted more. The specific formula used in DDogleg is as follows:
\begin{equation}
D_k^{ii} = \max\left( d_{\bigtriangledown},\min\left( \sqrt{|B_k^{ii}|} , d_{\bigtriangleup} \right)\right)
\end{equation}
where $d_{\bigtriangledown}$ is the minimum allowed scaling value and $d_{\bigtriangleup}$ is the maximum. This approach can handle negative definite $B_k$ and has the desirable property \cite{dennis1996} that the diagonal elements in $\tilde{B}_k = D^{-1}B_k D^{-1}$ will typically be $\tilde{B}_k^{ii} \approx 1$, unless clamped or $B_k^{ii}$ is zero. From a numerical perspective, matrices with this property are properly scaled to reduce overflow and can be decomposed with high precision. When configured to automatically scale, DDogleg will update its scaling at every iteration.

There are two primary ways for the user to specify their own scaling in DDogleg. 1) They can pre-scale the data and adjust their forumlas. 2) They can provide a scaling vector which contains the diagonal elements in $D$. The former is arguably the best way while the later is easier. If the former is done then automatic scaling can still be applied, ensuring that the Hessian matrix is well suited for decomposition. A third option, for advanced users, is to override a class in DDogleg and change the scaling to any arbitrary function you wish.

Most of the literature recommends always properly scaling. In practice people only do so after not converging to a correct solution. Applying automatic scaling does not always improve performance. It can even cause the search to get stuck in a local minimum by changing the trajectory. We suggest the following steps when trying to determine if scaling issues are causing the search to fail:
\begin{enumargin}{0.2}
\item Try without scaling. If this works stop.
\item Double check your math. If an error is found start again.
\item Try with automatic scaling. If this works stop.
\item Try try tuning $d_{\bigtriangledown}$ and $d_{\bigtriangleup}$ more. If this works stop.
\item Scale the problem prior to passing it to DDogleg. If this works stop.
\item Double check your math. If an error is found start again.
\item Turn on automatic scaling and see if things improve. If this works stop.
\item Accept your fate, read the literature, step through the code line by line in a debugger.
\item Submit a scathing bug report
\item Find the type-o in your math
\end{enumargin}

\subsubsection{Initial Region Size} 
\label{section:init_region_size}

Selection of the initial trust region size $\Delta_0$ is important but typically not discussed in reference material \cite{fletcher1987,numopt2006,IMM2004} in detail. Initial region size is typically considered a tuning parameter that the user is supposed to select through trial and error. While the Trust region size is dynamically adjusted at each iteration in the Trust Region approach, the initial selection of the trust region size can significantly influence the final convergence.

Here is an example of a possible failure mode when the trust region's size is poorly selected. With the Dog Leg method, if $\Delta_0$ is too small then a Cauchy step is selected for several iterations. The Cauchy Point is often highly suboptimal and can lead the search down a poor path and incerases the odds of it getting stuck in local minimum. 

DDogleg provides two automatic methods for finding the initial region size. 1) \emph{Uncontrained initial step} and 2) \emph{Cauchy initial step}. With the unconstrained method the selected algorithm for choosing a step is given a trust region of MAX\_VALUE. The step it selects is used and the trust region is then set to the length of that step. This works well in many problems but can be overly agressive in a few causing the optimization to get stuck. The Cauchy initial step method computes the length of a Cauchy step, then sets the region size to be 10x that. This estimate tends to be conservative will in general converge but can make convergence slow.

If the automatic methods fail to produce acceptable results then manual tuning will be necissary. One possible manual tuning procedure is to start with $\Delta_0=1$ then trying $\Delta_0=100$, and if results improved try $\Delta_0=10000$. If results don't get better try $0.1$ or other fractions of one. Setting $\Delta_0$ to excessively large numbers is also problematic because when a step fails it can take numerious iterations to recover, slowing down convergence. Also increasing the possibility of the search jumping into a flat plateau far away and getting stuck. 

Recommended Procedure for Selection of Initial Trust Region Size:
\begin{enumargin}{0.2}
\item Turn on verbose output so that progress and step size are visible
\item Start with automatic selection using \emph{unconstrained initial step}
\item If unconstrained method selected a very large step size and got stuck try \emph{Cauchy initial step}
\item If performance is still poor follow manual tuning procedure
\end{enumargin}

For instructions on how to switch between the methods described here consult the JavaDoc of ConfigTrustRegion.

\subsubsection{Cauchy Point}
\label{section:cauchy} 

The Caunch Point $p^s_k$ is the end point of line segment which starts at $p=0$, pointing in along the direction of unit vector $\hat{p}^s_k$, and is length $\tau_k$. In other words $p^s_k = \tau \hat{p}^s_k$. The unknown $\hat{p}^s_k$ is found by solving the subproblem Eq. \ref{eq:trust_region_subproblem} with only the linear terms:
\begin{equation}
\begin{array}{lr}
\hat{p}^s_k = \min\limits_{p\in \R^n} f_k + g_k^T p & s.t. \norm{p} \le \Delta_k
\end{array}
\end{equation}
The line segment length is found by minimizing Eq. \ref{eq:trust_region_subproblem} along direction $\hat{p}^s_k$
\begin{equation}
\begin{array}{lr}
\tau_k = \min\limits_{\tau \ge 0} m_k(\tau v^s_k) & s.t. \norm{\tau v^s_k} \le \Delta_k
\end{array}
\end{equation}

The solution (see Chapter 4 of \cite{numopt2006} for details and diagrams) is as follows:
\begin{equation}
p^s_k = -\tau_k \frac{\Delta_k}{\norm{g_k}}g_k
\label{eq:cauchy_p}
\end{equation}
\begin{equation}
\tau_k = 
	\begin{cases}
		\quad 1 & g_k^T B_k g_k \le 0 \\
		\quad \min\left(1,\norm{g_k}^3/(\Delta_k g_k^T B_k g_k)\right) & g_k^T B_k g_k > 0
	\end{cases}
	\label{eq:cauchy_tau}
\end{equation}

The formulas in (\ref{eq:cauchy_p}) and (\ref{eq:cauchy_tau}) can be improved upon to avoid numerical overflow issues by removing powers of three and division by the step size:
\begin{eqnarray}
\hat{g}_k &=& \frac{g_k}{\norm{g_k}} \\
p^s_k &=& -\bar{\tau}_k \hat{g}_k
\end{eqnarray}
\begin{equation}
\bar{\tau}_k = \begin{cases}
		\quad \Delta_k & \hat{g}_k^T B_k \hat{g}_k\le 0 \\
		\quad \min\left(\Delta_k,\norm{g_k}/(\hat{g}_k^T B_k \hat{g}_k)\right) & \hat{g}_k^T B_k \bar{g}_k > 0
	\end{cases}
\end{equation}
The predicted reduction in score is found using:
\begin{equation}
m_k(\bm{0})-m_k(\bm{p}_k) = \tau_k\left(\norm{g_k} - \frac{\tau_k \hat{g}_k^T B_k \hat{g}_k}{2} \right)
\end{equation}


\subsubsection{Dogleg}
\label{section:dogleg}  

Dogleg improves upon the Cauchy Point by considering second order terms to provide a more accurate solution to Eq. \ref{eq:trust_region_subproblem}. The optimal solution, as a function of region size, is a curved trajectory. The Dogleg method approximates this curved trajectory using two line segmets. The first line starts at the $p_k$ and moves along the steepest descent direction and the second heads towards $p^b$ the solution to the unconstrained version of (\ref{eq:trust_region_subproblem}). As with equations from Cauchy Point, these equations have been reforumated to avoid powers of three and are not identical to \cite{numopt2006,IMM2004}.
\begin{eqnarray}
\hat{g_k} &=& \frac{g_k}{\norm{g_k}} \\
p^u_k &=& -\frac{g_k}{\hat{g_k}^T B_k \hat{g_k}} \\
p^b_k &=& -B^{-1}_k g_k \\
p^{dog}_k &=&
\begin{cases}
	\tau p^u_k & 0 \le \tau < 1 \\
	p^u_k + (\tau -1)(p^b_k-p^u_k) & 1 \le \tau \le 2
\end{cases}
\end{eqnarray}
where $B_k$ is positive definite, and $p^{dog}_k$ is the point selected by the Dogleg method. The solution to $\tau$ can be easily found by solving along each line segment. If $B_k$ is not positive definite then the Cauchy Point algorithm is used instead.

\begin{algorithm}{}
\caption{\label{alg:dogleg_step}Selection of Dogleg Step}
\begin{algorithmic}[1]
	\State Write this algorithm out
\end{algorithmic}
\end{algorithm}

\subsection{Schur Complement}
It is possible to take advantage of the sparse structure in certain problems to greatly reduce computational cost. The Schur Complement provides a mechanism where the computational cost of inverting matrices with certain structures can be greatly reduced. Bundle Adjustment is one such problem \cite{triggs1999bundle}. 

Bundle adjustment naturely has a sparse structure \cite{triggs1999bundle} but even if optimized by a sparse matrix library solving can be quite slow due to fill in during matrix decomposition, making the sparse matrix much less sparse. Use of the Schur Complement enables the system's structure to be taken advantage of greatly increasing the speed of computations.

Let $M$ be a square matrix which has been broken up into four submatrices. It will have the following factorization:
\begin{equation}
M = \begin{bmatrix}
A & B \\
C & D
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 \\
C A^{-1} 1
\end{bmatrix}
\begin{bmatrix}
A & 0 \\
0 & \bar{D}
\end{bmatrix}
\begin{bmatrix}
1 & A^{-1}B \\
0 & 1
\end{bmatrix}
\end{equation}
It can then be shown that
\begin{equation}
\bar{D} = D - C A^{-1}B
\end{equation}
This is known as the Schur complement of the block A of matrix M. The Schur comlpement of block D of matrix M can also be found:
\begin{equation}
\bar{A} = A - B D^{-1}C
\end{equation}
We will discuss the former but the later can be useful too depending on the matrix structure. You will want to use the formulation which reduces the size of the matrix which needs to be inverted.

These relationships can then be used to solve the following system:
\begin{equation}
\begin{bmatrix}
A & B \\
C & D
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
b_1 \\ b_2
\end{bmatrix}
\end{equation}

\begin{algorithm}{}
\caption{\label{alg:schur_complement}Schur Complement to solve a reduced system}
\begin{algorithmic}[1]
	\State $\bar{D} = D - C A^{-1} B$
	\State $\bar{b}_2 = b_2 - C A^{-1} b_1$  
	\State $\bar{D} x_2 = \bar{b}_2$         \Comment{Reduced System}
	\State $A x_1 = b_1 - B x_2$
\end{algorithmic}
\end{algorithm}

For the least squares problem the Schur Complement is applied to the Jacobian based estimation of the Hessian:
\begin{equation}
J^T J =
\begin{bmatrix}
A & B \\
B^T & D
\end{bmatrix}
\end{equation}
This symmetry can be taken advantage of in matrix multiplication and when solving the system, which DDogleg does. DDogleg provides a specialized function for computing the Jacobian that splits it into a left and right side. This makes computation of the inner matrices more efficient and easier to apply.


\section{Unconstrained Minimization}

\begin{table}[h]
\centering
\caption{\label{definitions:UM}Definitions and API for Unconstrained Minimization}
\begin{tabular}{cl}
\textit{FunctionNtoS} & Interface for $f(\bm{x})$ \\
\textit{FunctionNtoN} & Interface for $g(\bm{x})$ \\
\textit{UnconstrainedMinimization} & Interface for unconstrained minimization
\end{tabular}
\end{table}

\begin{table}[h]
\caption{\label{summary:UM}Summary of Unconstrained Minimization Methods.}
\centering
\begin{tabular}{lcccccc}
Method & Iteration & Convergence & Singular & Negative-Definite & Dense & Sparse \\[1ex]
\hline
Quasi-Newton BFGS & $O(N^2)$ & Super Linear & ? & ? & Yes &  \rule{0pt}{2.6ex} \\
Trust Region BFGS Cauchy & $O(N^2)$ & Linear & Yes & Yes & Yes &  \\
Trust Region BFGS Dogleg & $O(N^2)$ & Super Linear & [1] & [1] & Yes &  \\
Quasi-Newton L-BFGS & ? & Super Linear & ? & ? &   & Yes \\
Trust Region L-BFGS Cauchy & ? &  Linear & Yes & Yes &  & Yes \\
Trust Region L-BFGS Dogleg & ? &  Super Linear & [1] & [1] &  & Yes \\[1ex]
\hline
\multicolumn{6}{l}{
\begin{minipage}{0.6\textwidth}
\centering
\vspace{2mm}
\begin{itemize}[leftmargin=*]
\item \emph{Iteration:} Runtime complexity of update step. $N$ is number of parameters.
\item \emph{Convergence:} how fast it converged.
\item \emph{Singular:} indicates that it can process singular systems.
\item \emph{Negative-Definite:} indicate that it can process negative definite systems
\item \emph{Dense} and \emph{Sparse:} indicate that dense and/or sparse matrices can be processed. 
\item {[1]} Switches to Cauchy in this situation.
\end{itemize}
\end{minipage}
 }
\end{tabular}
\end{table}

Describe unconstrained minimzation at a high level


\subsection{Convergence Test}

All unconstrained minimization algorithms in DDogleg use the same convergence tests. F-test checks the function's value to see if it has converged. G-test checks the gradient to see if it has converged. To disable a test assign it a value less than zero.

\begin{center}
\begin{tabular}{lc}
F-test & $ftol  \leq 1 - f(x+p)/f(x)$ \\
G-test & $gtol \leq \norm{\bm{g}(x)}_\infty$ \\
\end{tabular}
\end{center}
 
\subsection{Hessian Approximation} 

Unconstrianed minimization techniques need a way to estimate the Hessian. Exact methods of calculating the Hessian can be difficult to derive and expensive to compute. Algorithms which utilize exact methods have faster convergence but this is often offset by additional computational cost \cite{numopt2006}. DDogleg uses gradient based methods for estimating the Hessian. DFP \cite{davidonDFP} to estimate the Hessian and BFGS (Broyden-Fletcher-Goldfarb-Shanno) \cite{fletcher1987,numopt2006}\footnote{A quick search failed to assertain the first paper that fully described BFGS. What appears to be a precursor is discussed in \cite{fletcher1987} and \cite{numopt2006} fully describes the method but provides no citations.} to estimate the inverse hessian.

\begin{flalign}
\text{DFP} && \bm{B}_{k+1} &= (I- \rho_k \gamma_k s_k^T) \bm{B}_k (I - \rho_k s_k \gamma_k^T) + \rho_k \gamma_k \gamma_k^T && \\
\text{BFGS} && \bm{H}_{k+1} &= H_k - \frac{H_k \gamma_k \gamma_k^T H_k }{\gamma_k^T H_k \gamma y_k} + \frac{s_k s_k^T}{y_k^T s_k} &&
\end{flalign}
\begin{equation*}
\rho_k=\frac{1}{\gamma_k^T s_k}
\end{equation*}
where $H_k = B_k^{-1}$, $s_k = x_{k+1}-x_k$, and $y_k = \nabla f_{k+1} - \nabla f_k$.

DDogleg does not explictly provide support for using an exact Hessian. If you wish to use an exact Hessian this can be accomplished with a bit of coding by extending base classes in DDogleg. Search code for where BFGS is being used, extend that class, and override the function where the Hessian is estimated. For example, \textit{UnconMinTrustRegionBFGS} can be used to create your own exact Hessian unconstrained minimization trust region implementation.

\subsection{Trust Region}

Implementation Details:
\begin{enumargin}{0.2}
    \item The Hessian is initialized with an identity matrix. 
	\item The Hessian and inverse is iteratively approximated using DFP and BFGS.
	\item The Hessian is only updated when the Wolfe condition is meet
	\item Dogleg-BFGS avoids $O(N^3)$ matrix decomposition by computing the inverse Hessian directly with BFGS in $O(N^2)$ time.
\end{enumargin}

Future Work:
\begin{enumargin}{0.2}
	\item Remove the need to compute $B_k$ and $H_k$ by directly computing the Cholesky factors of $B_k$. 
	\item \cite{numopt2006} recommends against skipping updates to the Hessian when Wolfe is not meet and suggests using a damped BFGS instead.
\end{enumargin}

\section{Unconstrained Least-Squares}
\begin{table*}[h]
\centering
\begin{tabular}{cl}
$\bm{x}$ & Parameter vector which is being optimized and has $n$ elements. $x \in \R^n$ \\
$f(\bm{x})$ & Scalar error function being optimized. $f \ge 0$ \\
$f_k$ & $f(\bm{x}_k)$ \\
$\bm{F}(\bm{x})$ &  Residual function from $\mathbb{R}^n \rightarrow \R^m$ \\
\textit{FunctionNtoM} & Interface for $\bm{F}(\bm{x})$ \\
$\bm{J}(\bm{x})$ & Jacobian of residual function \\
\textit{FunctionNtoMxN} & Interface for $\bm{J}(\bm{x})$ \\
 & Can be computed numerically \\
$g(\bm{x})$ & Gradient of $f(\bm{x})$, which is $\bm{J}(\bm{x})^T  \bm{F}(\bm{x})$ \\
$g_k$ & $g(\bm{x}_k)$ \\
\textit{UnconstrainedLeastSquares} & High level interface for this unconstrained least squares
\end{tabular}
\caption{\label{definitions:UNLS}Definitions and API for Unconstrained Nonlinear Least-Squares}
\end{table*}

Unconstrained Least-Squares is a special case of Unconstrained Minimization. It refers to a problem where the function being optimized has the form
\begin{equation}
\min\limits_{\bm{x}} f(\bm{x})=\frac{1}{2}\sum^m_{j=1} r^2_j(\bm{x})
\end{equation}
where $r_j(\bm{x})$ is a scalar function which outputs the residual or error and by definition $f(\bm{x}) \ge 0$. When implemented, instead of a set of scalar functions $r_j$ a single column vector function $\bm{F}(\bm{x}) = [ r_1(\bm{x}) , r_2(\bm{x}) , \cdots , r_m(\bm{x}) ]^T$ is written and the problem being solved can be restated as
\begin{eqnarray}
\min\limits_{\bm{x}} f(\bm{x})&=&\frac{1}{2} \bm{F}(\bm{x})^T \bm{F}(\bm{x})\\
&=& \frac{1}{2} \norm{\bm{F}(\bm{x})}^2_2
\end{eqnarray}

The Jacobian can then be defined as
\begin{eqnarray}
\bm{J}(\bm{x}) &=& \left[\frac{\partial r_j}{\partial x_i}\right]\begin{array}{l}j=1,\cdots,m\\i=1,\cdots,n \end{array} \\
&=& \left[ \begin{array}{c}\nabla r_1(\bm{x})^T \\ \nabla r_2(\bm{x})^T \\ \vdots \\ \nabla r_m(\bm{x})^T \end{array}\right] \\
\nabla r_j(\bm{x})^T &=& \left[ \frac{\partial r_j}{\partial x_1},\frac{\partial r_j}{\partial x_2}, \cdots , \frac{\partial r_j}{\partial x_n} \right]^T
\end{eqnarray}
and the Gradient as
\begin{eqnarray}
\nabla f(\bm{x}) &=& \sum^m_{j=1}r_j(\bm{x})\nabla r_j(\bm{x}) \\
&=& \bm{J}(\bm{x})^T \bm{F}(\bm{x})
\end{eqnarray}

\subsection{Convergence Test}
\begin{center}
\begin{tabular}{lc}
F-test & $ftol \leq \norm{\bm{F}_k-\bm{F}_{k-1}}_\infty$ \\
G-test & $gtol \leq \norm{\bm{g}(x)}_\infty$ \\
\end{tabular}
\end{center}

\subsection{Levenberg}


\subsection{Levenberg-Marquardt}

\subsection{Trust Region}

When trust region methods are applied to least-squares problems they are defined as follow:

\begin{eqnarray}
f_k &=& f(\bm{x}+\bm{p}) \\
J_k &=& J(\bm{x}+\bm{p}) \\
\bm{g}_k &=& J^T_k F_k  \\
\bm{B}_k &=& J_k^T J_k
\end{eqnarray}


\subsection{Dense and Sparse}

\subsection{Shur Complement}

\bibliographystyle{IEEEtran}
\bibliography{mybib}


\end{document}
